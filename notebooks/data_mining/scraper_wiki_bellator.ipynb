{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_df(url):\n",
    "    soup = BeautifulSoup(requests.get(url).text,\"html.parser\")\n",
    "    \n",
    "    table = soup.find_all(\"table\", class_ = \"sortable\")[0]\n",
    "    table_rows = table.find_all(\"tr\")[1:]\n",
    "    anchors = [_.find_all(\"a\") for _ in table_rows if len(_.find_all(\"a\"))>0]\n",
    "    \n",
    "    cols = [\"link\", \"name\"]\n",
    "    links_df = pd.DataFrame([(anchor[0].get(\"href\"), anchor[0].text) for anchor in anchors], columns=cols)\n",
    "    \n",
    "    return links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanResults(result):\n",
    "    event_name = result[\"event\"]\n",
    "    df = result[\"df\"]\n",
    "    df.columns = [_[1] for _ in df.columns]\n",
    "\n",
    "    split_by_card = [(i, df.iloc[i,0]) for i in df[df.eq(df.iloc[:, 0], axis=0).all(axis=1)].index]\n",
    "    if 0 not in [_[0] for _ in split_by_card]:\n",
    "        split_by_card = [(0, \"Main card\"), *split_by_card]\n",
    "\n",
    "    for i in range(len(split_by_card)-1):\n",
    "        split_by_card[i] = (split_by_card[i][0], split_by_card[i+1][0], split_by_card[i][1])\n",
    "\n",
    "    split_by_card[-1] = (split_by_card[-1][0], len(df), split_by_card[-1][1])\n",
    "\n",
    "    sdfs = []\n",
    "    for start, end, card in split_by_card:\n",
    "        sdf = df.iloc[start:end, :]\n",
    "        sdf = sdf.assign(fight_card = card)\n",
    "        sdfs.append(sdf)\n",
    "    \n",
    "    df = pd.concat(sdfs).drop([i[0] for i in split_by_card[1:]]).reset_index(drop=True)\n",
    "\n",
    "    cols2rename = {\n",
    "        x: x.lower().replace(' ', '_') for x in df.columns\n",
    "    }\n",
    "\n",
    "    cols2rename = {\n",
    "        **cols2rename,\n",
    "        **{\n",
    "            \"Unnamed: 1_level_1\": \"winner\",\n",
    "            \"Unnamed: 3_level_1\": \"loser\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    df.rename(columns=cols2rename, inplace=True)\n",
    "\n",
    "    df.drop(columns=[\"unnamed:_2_level_1\"], axis=1, inplace=True)\n",
    "\n",
    "    df = df.assign(event_name = event_name)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_details(event, table_class, url):\n",
    "    event_name = event.text.replace(\"[edit]\", \"\")\n",
    "    tables = event.find_next(\"table\", class_ = table_class)\n",
    "    if tables != None:\n",
    "        df = pd.read_html(str(tables))\n",
    "    else:\n",
    "        df = pd.read_html(str(event.find_next(\"table\", class_ = \"wikitable\")))\n",
    "    \n",
    "    df = df[0]\n",
    "    df = cleanResults(result={\"event\": event_name, \"df\": df})\n",
    "    df = df.assign(link = url)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData_bellator(url):\n",
    "    dfs = []\n",
    "    soup = BeautifulSoup(requests.get(url).text, features=\"lxml\")\n",
    "    header_patterns = [\"bellator\"]\n",
    "    pattern_match = lambda x: len([_ for _ in header_patterns if _ in x.lower()]) > 0\n",
    "\n",
    "    # event_headers = soup.find_all(lambda tag: tag.name == \"h2\" and \"one\" in tag.text.lower() and \"cancelled\" not in tag.text.lower())\n",
    "    event_headers = [\n",
    "        header for header in soup.find_all(\n",
    "        lambda tag: \n",
    "        tag.name == \"h2\" and \"cancelled\" not in tag.text.lower() and \"tournament\" not in tag.text.lower()\n",
    "        ) if pattern_match(header.text)\n",
    "        ]\n",
    "\n",
    "    if not event_headers:\n",
    "        event_headers = soup.find_all(lambda tag: tag.name == \"h1\" and \"bellator\" in tag.text.lower() and \"cancelled\" not in tag.text.lower())\n",
    "    \n",
    "    table_classes = [_.get(\"class\") for _ in event_headers[0].find_all_next(\"table\")]\n",
    "\n",
    "    table_class = \"wikitable\" if \"toccolours\" not in [x for xs in list(filter(lambda x: x!=None, table_classes)) for x in xs] else \"toccolours\"\n",
    "\n",
    "    for event in event_headers:\n",
    "        try:\n",
    "            df = event_details(event, table_class, url)\n",
    "            dfs.append(df)\n",
    "        except:\n",
    "            print(event.text)\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_Bellator_MMA_events'\n",
    "links_df = get_links_df(url)\n",
    "\n",
    "clean_link = lambda x: f\"https://en.wikipedia.org/{x.split('#')[0]}\"\n",
    "links_df[\"link_clean\"] = links_df[\"link\"].apply(clean_link)\n",
    "links = links_df[\"link_clean\"].value_counts().reset_index().iloc[:,0]\n",
    "links = links.to_list()\n",
    "\n",
    "dfs = []\n",
    "failed_links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org//wiki/Bellator_22']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[link for link in links if \"bellator_22\" in link.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bellator 26[edit]\n",
      "Bellator 27[edit]\n",
      "Bellator 28[edit]\n",
      "Bellator 29[edit]\n",
      "Bellator 30[edit]\n",
      "Bellator 31[edit]\n",
      "Bellator 32[edit]\n",
      "Bellator 33[edit]\n",
      "Bellator 34[edit]\n"
     ]
    }
   ],
   "source": [
    "df = getData_bellator('https://en.wikipedia.org//wiki/Bellator_22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All objects passed were None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd\u001b[39m.\u001b[39;49mconcat([\u001b[39mNone\u001b[39;49;00m,\u001b[39mNone\u001b[39;49;00m], ignore_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\paulm\\anaconda3\\envs\\ultimateNakMuay\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    370\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    373\u001b[0m     objs,\n\u001b[0;32m    374\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    375\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m    376\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[0;32m    377\u001b[0m     keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[0;32m    378\u001b[0m     levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[0;32m    379\u001b[0m     names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    380\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m    381\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    382\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    383\u001b[0m )\n\u001b[0;32m    385\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\paulm\\anaconda3\\envs\\ultimateNakMuay\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:452\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    449\u001b[0m         keys \u001b[39m=\u001b[39m Index(clean_keys, name\u001b[39m=\u001b[39mname, dtype\u001b[39m=\u001b[39m\u001b[39mgetattr\u001b[39m(keys, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    451\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 452\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll objects passed were None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    454\u001b[0m \u001b[39m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    455\u001b[0m ndims \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: All objects passed were None"
     ]
    }
   ],
   "source": [
    "pd.concat([None,None], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultimateNakMuay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
